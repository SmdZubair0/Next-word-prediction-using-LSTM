{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n5WVjsXyQ-uL"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9vp26YMJQ-uP"
      },
      "outputs": [],
      "source": [
        "# reading text\n",
        "\n",
        "with open(\"/content/1661-0.txt\",\"r\",encoding='utf-8') as f:\n",
        "    text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXwRViTjQ-uR",
        "outputId": "362435be-76d0-48db-933c-833d83e422dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "580619"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "len(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6iGZOlxBQ-uT"
      },
      "outputs": [],
      "source": [
        "# dividing sentence\n",
        "sen = text.split('.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IN_wOqReQ-uT"
      },
      "outputs": [],
      "source": [
        "# take only valid sentences\n",
        "sen = [i for i in sen if len(i) > 10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeeMui6sQ-uU",
        "outputId": "5b3e8273-f10e-499f-ba8a-7a3acb822d94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6107"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "len(sen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NxaeaiG3Q-uV"
      },
      "outputs": [],
      "source": [
        "# remove escape sequence\n",
        "sen = [i.replace('\\n',\" \") for i in sen]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6twfu8sNQ-uV"
      },
      "outputs": [],
      "source": [
        "sen = [i.replace(\"—\",\" \") for i in sen]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1WyximtcQ-uW"
      },
      "outputs": [],
      "source": [
        "puncs = string.punctuation\n",
        "\n",
        "trans = str.maketrans(\"\",\"\",puncs)\n",
        "sen = [i.translate(trans) for i in sen]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7SSF17aKQ-uW"
      },
      "outputs": [],
      "source": [
        "pattern = r'[“”‘’—…]'\n",
        "\n",
        "sen = [re.sub(pattern,\"\",i) for i in sen]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xZ5AN73PQ-uX"
      },
      "outputs": [],
      "source": [
        "sen = [i.strip() for i in sen]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nhS9XjP1Q-uX"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "vpJf0SW4RZYn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(sen)"
      ],
      "metadata": {
        "id": "XahTHS6BRcqY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "\n",
        "index_word = {j:i for i,j in word_index.items()}"
      ],
      "metadata": {
        "id": "mbPyvcfURgkl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = len(tokenizer.word_index) + 1\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRyKaOuqRivK",
        "outputId": "9caa41f1-af97-447b-cd6f-1e5b9093ccdc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8532"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = max([len(i.split()) for i in sen])\n",
        "maxlen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wio_niS5RpuX",
        "outputId": "0e8286ac-f710-46ea-ef14-bef07b22faa8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "101"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq = []\n",
        "\n",
        "for i in sen:\n",
        "    tok = tokenizer.texts_to_sequences([i])[0]\n",
        "\n",
        "    for j in range(1,len(tok)):\n",
        "        seq = tok[:j+1]\n",
        "        input_seq.append(seq)"
      ],
      "metadata": {
        "id": "wVqv-mxZSFD5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pad_seq = pad_sequences(input_seq,maxlen=maxlen,padding='pre')"
      ],
      "metadata": {
        "id": "N0GQ5vusUXXd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = pad_seq[:,:-1]\n",
        "y = pad_seq[:,-1]"
      ],
      "metadata": {
        "id": "ujMogPCyVM7n"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = to_categorical(y,num_classes=vocab)"
      ],
      "metadata": {
        "id": "60seVRlwVnlz"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding,LSTM,Dense"
      ],
      "metadata": {
        "id": "JBPW6cykV-ZC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(vocab,100,input_length=maxlen-1))\n",
        "model.add(LSTM(150,return_sequences=True))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(vocab,activation='softmax'))"
      ],
      "metadata": {
        "id": "FbkQjeRDWACN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cHqNp7qWUuX",
        "outputId": "8f4ed173-5a32-4141-9177-aad007d0957b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 100)          853200    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100, 150)          150600    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 150)               180600    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 8532)              1288332   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2472732 (9.43 MB)\n",
            "Trainable params: 2472732 (9.43 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "wdtCaopEWpKA"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = model.fit(x,y,epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8S1pNgO6WuMa",
        "outputId": "73516636-5cac-4956-916e-d3009678732c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3163/3163 [==============================] - 83s 24ms/step - loss: 6.4149 - accuracy: 0.0720\n",
            "Epoch 2/10\n",
            "3163/3163 [==============================] - 48s 15ms/step - loss: 5.7231 - accuracy: 0.1096\n",
            "Epoch 3/10\n",
            "3163/3163 [==============================] - 46s 15ms/step - loss: 5.3745 - accuracy: 0.1311\n",
            "Epoch 4/10\n",
            "3163/3163 [==============================] - 46s 14ms/step - loss: 5.1206 - accuracy: 0.1430\n",
            "Epoch 5/10\n",
            "3163/3163 [==============================] - 49s 15ms/step - loss: 4.9122 - accuracy: 0.1543\n",
            "Epoch 6/10\n",
            "3163/3163 [==============================] - 52s 16ms/step - loss: 4.7284 - accuracy: 0.1624\n",
            "Epoch 7/10\n",
            "3163/3163 [==============================] - 50s 16ms/step - loss: 4.5558 - accuracy: 0.1693\n",
            "Epoch 8/10\n",
            "3163/3163 [==============================] - 44s 14ms/step - loss: 4.3918 - accuracy: 0.1754\n",
            "Epoch 9/10\n",
            "3163/3163 [==============================] - 46s 15ms/step - loss: 4.2365 - accuracy: 0.1840\n",
            "Epoch 10/10\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 4.0883 - accuracy: 0.1932\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h2 = model.fit(x,y,epochs=100,initial_epoch=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gigeu9K7YadJ",
        "outputId": "f961e360-ba68-4cfa-833a-acdf4b6b594b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/100\n",
            "3163/3163 [==============================] - 45s 14ms/step - loss: 3.9532 - accuracy: 0.2029\n",
            "Epoch 12/100\n",
            "3163/3163 [==============================] - 42s 13ms/step - loss: 3.8263 - accuracy: 0.2158\n",
            "Epoch 13/100\n",
            "3163/3163 [==============================] - 44s 14ms/step - loss: 3.7096 - accuracy: 0.2277\n",
            "Epoch 14/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 3.5996 - accuracy: 0.2414\n",
            "Epoch 15/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 3.4971 - accuracy: 0.2552\n",
            "Epoch 16/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 3.4011 - accuracy: 0.2696\n",
            "Epoch 17/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 3.3102 - accuracy: 0.2817\n",
            "Epoch 18/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 3.2261 - accuracy: 0.2949\n",
            "Epoch 19/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 3.1440 - accuracy: 0.3069\n",
            "Epoch 20/100\n",
            "3163/3163 [==============================] - 44s 14ms/step - loss: 3.0675 - accuracy: 0.3204\n",
            "Epoch 21/100\n",
            "3163/3163 [==============================] - 43s 13ms/step - loss: 2.9945 - accuracy: 0.3329\n",
            "Epoch 22/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 2.9225 - accuracy: 0.3444\n",
            "Epoch 23/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 2.8511 - accuracy: 0.3579\n",
            "Epoch 24/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 2.7846 - accuracy: 0.3694\n",
            "Epoch 25/100\n",
            "3163/3163 [==============================] - 44s 14ms/step - loss: 2.7187 - accuracy: 0.3820\n",
            "Epoch 26/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 2.6629 - accuracy: 0.3932\n",
            "Epoch 27/100\n",
            "3163/3163 [==============================] - 44s 14ms/step - loss: 2.6003 - accuracy: 0.4026\n",
            "Epoch 28/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 2.5422 - accuracy: 0.4150\n",
            "Epoch 29/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 2.4834 - accuracy: 0.4254\n",
            "Epoch 30/100\n",
            "3163/3163 [==============================] - 46s 14ms/step - loss: 2.4297 - accuracy: 0.4360\n",
            "Epoch 31/100\n",
            "3163/3163 [==============================] - 45s 14ms/step - loss: 2.3740 - accuracy: 0.4468\n",
            "Epoch 32/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 2.3234 - accuracy: 0.4573\n",
            "Epoch 33/100\n",
            "3163/3163 [==============================] - 44s 14ms/step - loss: 2.2727 - accuracy: 0.4677\n",
            "Epoch 34/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 2.2237 - accuracy: 0.4778\n",
            "Epoch 35/100\n",
            "3163/3163 [==============================] - 44s 14ms/step - loss: 2.1765 - accuracy: 0.4880\n",
            "Epoch 36/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 2.1297 - accuracy: 0.4986\n",
            "Epoch 37/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 2.0846 - accuracy: 0.5075\n",
            "Epoch 38/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 2.0405 - accuracy: 0.5162\n",
            "Epoch 39/100\n",
            "3163/3163 [==============================] - 42s 13ms/step - loss: 2.0013 - accuracy: 0.5255\n",
            "Epoch 40/100\n",
            "3163/3163 [==============================] - 44s 14ms/step - loss: 1.9591 - accuracy: 0.5352\n",
            "Epoch 41/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 1.9178 - accuracy: 0.5430\n",
            "Epoch 42/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 1.8791 - accuracy: 0.5515\n",
            "Epoch 43/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 1.8418 - accuracy: 0.5602\n",
            "Epoch 44/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 1.8062 - accuracy: 0.5688\n",
            "Epoch 45/100\n",
            "3163/3163 [==============================] - 42s 13ms/step - loss: 1.7701 - accuracy: 0.5768\n",
            "Epoch 46/100\n",
            "3163/3163 [==============================] - 44s 14ms/step - loss: 1.7364 - accuracy: 0.5828\n",
            "Epoch 47/100\n",
            "3163/3163 [==============================] - 44s 14ms/step - loss: 1.7032 - accuracy: 0.5908\n",
            "Epoch 48/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 1.6733 - accuracy: 0.5973\n",
            "Epoch 49/100\n",
            "3163/3163 [==============================] - 44s 14ms/step - loss: 1.6393 - accuracy: 0.6051\n",
            "Epoch 50/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 1.6095 - accuracy: 0.6126\n",
            "Epoch 51/100\n",
            "3163/3163 [==============================] - 45s 14ms/step - loss: 1.5814 - accuracy: 0.6188\n",
            "Epoch 52/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 1.5533 - accuracy: 0.6251\n",
            "Epoch 53/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 1.5248 - accuracy: 0.6309\n",
            "Epoch 54/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 1.4960 - accuracy: 0.6389\n",
            "Epoch 55/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 1.4720 - accuracy: 0.6440\n",
            "Epoch 56/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 1.4474 - accuracy: 0.6490\n",
            "Epoch 57/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 1.4413 - accuracy: 0.6493\n",
            "Epoch 58/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 1.4206 - accuracy: 0.6549\n",
            "Epoch 59/100\n",
            "3163/3163 [==============================] - 42s 13ms/step - loss: 1.3947 - accuracy: 0.6615\n",
            "Epoch 60/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 1.3701 - accuracy: 0.6679\n",
            "Epoch 61/100\n",
            "3163/3163 [==============================] - 42s 13ms/step - loss: 1.3476 - accuracy: 0.6722\n",
            "Epoch 62/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 1.3285 - accuracy: 0.6772\n",
            "Epoch 63/100\n",
            "3163/3163 [==============================] - 44s 14ms/step - loss: 1.3076 - accuracy: 0.6824\n",
            "Epoch 64/100\n",
            "3163/3163 [==============================] - 42s 13ms/step - loss: 1.2856 - accuracy: 0.6850\n",
            "Epoch 65/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 1.2674 - accuracy: 0.6913\n",
            "Epoch 66/100\n",
            "3163/3163 [==============================] - 42s 13ms/step - loss: 1.2472 - accuracy: 0.6966\n",
            "Epoch 67/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 1.2282 - accuracy: 0.7010\n",
            "Epoch 68/100\n",
            "3163/3163 [==============================] - 42s 13ms/step - loss: 1.2137 - accuracy: 0.7045\n",
            "Epoch 69/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 1.1941 - accuracy: 0.7091\n",
            "Epoch 70/100\n",
            "3163/3163 [==============================] - 45s 14ms/step - loss: 1.1770 - accuracy: 0.7125\n",
            "Epoch 71/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 1.1887 - accuracy: 0.7090\n",
            "Epoch 72/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 1.2023 - accuracy: 0.7017\n",
            "Epoch 73/100\n",
            "3163/3163 [==============================] - 44s 14ms/step - loss: 1.1530 - accuracy: 0.7164\n",
            "Epoch 74/100\n",
            "3163/3163 [==============================] - 44s 14ms/step - loss: 1.1339 - accuracy: 0.7222\n",
            "Epoch 75/100\n",
            "3163/3163 [==============================] - 43s 13ms/step - loss: 1.1180 - accuracy: 0.7265\n",
            "Epoch 76/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 1.1040 - accuracy: 0.7289\n",
            "Epoch 77/100\n",
            "3163/3163 [==============================] - 44s 14ms/step - loss: 1.0903 - accuracy: 0.7323\n",
            "Epoch 78/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 1.0731 - accuracy: 0.7376\n",
            "Epoch 79/100\n",
            "3163/3163 [==============================] - 45s 14ms/step - loss: 1.0594 - accuracy: 0.7404\n",
            "Epoch 80/100\n",
            "3163/3163 [==============================] - 44s 14ms/step - loss: 1.0473 - accuracy: 0.7438\n",
            "Epoch 81/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 1.0357 - accuracy: 0.7457\n",
            "Epoch 82/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 1.0199 - accuracy: 0.7498\n",
            "Epoch 83/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 1.0115 - accuracy: 0.7524\n",
            "Epoch 84/100\n",
            "3163/3163 [==============================] - 44s 14ms/step - loss: 1.0447 - accuracy: 0.7394\n",
            "Epoch 85/100\n",
            "3163/3163 [==============================] - 43s 13ms/step - loss: 1.0193 - accuracy: 0.7474\n",
            "Epoch 86/100\n",
            "3163/3163 [==============================] - 44s 14ms/step - loss: 1.0016 - accuracy: 0.7531\n",
            "Epoch 87/100\n",
            "3163/3163 [==============================] - 43s 13ms/step - loss: 0.9883 - accuracy: 0.7560\n",
            "Epoch 88/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 0.9726 - accuracy: 0.7598\n",
            "Epoch 89/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 0.9635 - accuracy: 0.7616\n",
            "Epoch 90/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 0.9504 - accuracy: 0.7656\n",
            "Epoch 91/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 0.9426 - accuracy: 0.7676\n",
            "Epoch 92/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 0.9331 - accuracy: 0.7686\n",
            "Epoch 93/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 0.9179 - accuracy: 0.7735\n",
            "Epoch 94/100\n",
            "3163/3163 [==============================] - 42s 13ms/step - loss: 0.9117 - accuracy: 0.7746\n",
            "Epoch 95/100\n",
            "3163/3163 [==============================] - 44s 14ms/step - loss: 0.9965 - accuracy: 0.7539\n",
            "Epoch 96/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 0.9170 - accuracy: 0.7728\n",
            "Epoch 97/100\n",
            "3163/3163 [==============================] - 44s 14ms/step - loss: 0.9004 - accuracy: 0.7780\n",
            "Epoch 98/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 0.8922 - accuracy: 0.7775\n",
            "Epoch 99/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 0.8818 - accuracy: 0.7816\n",
            "Epoch 100/100\n",
            "3163/3163 [==============================] - 43s 14ms/step - loss: 0.8737 - accuracy: 0.7835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(r'model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFiSXQimYup3",
        "outputId": "df1e1986-43c5-44a8-c0b0-cc16e96835bf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"My marriage\"\n",
        "\n",
        "for i in range(10):\n",
        "    token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "    padded_token_text = pad_sequences([token_text], maxlen=maxlen-1, padding='pre')\n",
        "\n",
        "    pos = np.argmax(model.predict(padded_token_text))\n",
        "\n",
        "    text += \" \" + index_word[pos]\n",
        "    print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEGRrSkBYyN6",
        "outputId": "981e4278-3751-469c-f191-bc24398e9c26"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "My marriage had\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "My marriage had drifted\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "My marriage had drifted us\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "My marriage had drifted us away\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "My marriage had drifted us away from\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "My marriage had drifted us away from each\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "My marriage had drifted us away from each other\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "My marriage had drifted us away from each other ways\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "My marriage had drifted us away from each other ways smoking\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "My marriage had drifted us away from each other ways smoking and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VpZEwR1apgr_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}